import os
import sys
import yaml

sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(__file__))))))

from modules.lm_post_training.preprocessor_skeleton import PostTrainingPreprocessing as pp
from unittest import TestCase, main

class preProcessorTest(TestCase):
    
    # í´ë˜ìŠ¤ ìƒì„±ì‹œ í•œë²ˆë§Œ ì‹¤í–‰
    @classmethod
    def setUpClass(self):
        # ì„¤ì • íŒŒì¼ ë§Œë“¤ì–´ì§€ë©´ ê´€ë ¨ ë³€ìˆ˜ë¡œ ëŒ€ì²´í•  ê²ƒ
        with open('modules/config.yaml') as f:
            conf = yaml.safe_load(f)
        self.modelName = conf["model"]["name"]
        self.implPreProcessor = pp(self.modelName)
        self.dataPath = conf["dataset"]["post_training"]["test"]["path"]
        self.dataDom = conf["dataset"]["post_training"]["test"]["struct"].split('/')
        
        print("1:---ìµœì´ˆ ìƒì„± í…ŒìŠ¤íŠ¸---")
        assert self.implPreProcessor.getSize() == 0
        assert self.implPreProcessor.getRawData() == []
        print("1:---ìµœì´ˆ ìƒì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ---")
        print("2:---ìƒ˜í”Œ ë°ì´í„° ì…ë ¥ í…ŒìŠ¤íŠ¸---")
        
        self.implPreProcessor.readData(dataPath=self.dataPath, dataDOM=self.dataDom)
        assert self.implPreProcessor.getSize != 0
        assert self.implPreProcessor.getRawData() != []
        assert len(self.implPreProcessor.getRawData()) == self.implPreProcessor.getSize()
        
        print("í˜„ì¬ ë¶„ë¥˜ëœ ë¬¸ì¥ ê°œìˆ˜: " + str(self.implPreProcessor.getSize()))
        print(self.implPreProcessor.getRawData()[0])
        
        print("2:---ìƒ˜í”Œ ë°ì´í„° ì…ë ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ---")
        
    # í´ë˜ìŠ¤ ì†Œë©¸ì‹œ í•œë²ˆë§Œ ì‹¤í–‰
    @classmethod
    def tearDownClass(self):
        print("tearDownClass")
    
    # ê° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹¤í–‰ ì‹œ 
    def setUp(self):
        print('setUp')
    
    def tearDown(self):
        print('tearDown')
        
    def test_remove_special_characters(self):
        print("remove special character testing......")
        test_dataset = [" test ", "<html>test</html>", "abcdef123456@naver.com test", "!t@e#$s%t^&*()", "ğŸ˜€ğŸ˜ƒğŸ˜„tğŸ˜eğŸ˜†ğŸ˜…sğŸ˜‚t", "tã…”eã…”sã……tã…Œ", "ì „ì „ì „ì „ê¸ê¸ê¸ê¸", "t   e   s   t"]
        test_answer = ["test", "test", "test", "test", "test", "test", "ì „ì „ê¸ê¸", "t e s t"]
        clean_dataset = list(map(self.implPreProcessor.removeSpecialCharacters, test_dataset))
        self.assertEqual(clean_dataset, test_answer)
        print("Done!")
        #TODO
        
    def test_masking(self):
        print("masking testing......")        
        #TODO
    
    def test_tokenize(self):
        print("tokenize testing......")
        #TODO
        
    def test_masked_language_model(self):
        print("masked language model testing......")
        #TODO
        
    def test_next_sentence_prediction(self):
        print("get token data testing......")
        #NSPmodule ê¸°ë³¸ê°’
        self.implPreProcessor.nspMode.prob = 0.5
        self.assertEqual(self.implPreProcessor.nspMode.prob, 0.5)
        self.assertEqual(self.implPreProcessor.nspMode.setStrategy("NoStrategy"))


        testSize = 1000
        nspResult = self.implPreProcessor.nextSentencePrediction(testSize)

        # ì›í•˜ëŠ” ë¬¸ì¥ì˜ ê°œìˆ˜ë§Œí¼ í•´ë‹¹ ë¬¸ì„œìŒì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.
        self.assertEqual(testSize, len(nspResult))
        
        # ê° ë°ì´í„°ëŠ” ë¬¸ì„œìŒ ë°ì´í„°ì™€ í•´ë‹¹ ë¬¸ì œì˜ ì •ë‹µê°’ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        self.assertTrue("data" in nspResult[0])
        self.assertTrue("label" in nspResult[0])

        #í™•ë¥  í…ŒìŠ¤íŠ¸(ê¸°ë³¸ê°’ 50%)
        nextPredict = 0
        negPredict = 0
        for nspComponent in nspResult:
            if nspComponent.get('label'):
                nextPredict = nextPredict + 1
            else:
                negPredict = negPredict + 1
        self.assertEqual(nextPredict + negPredict, testSize)
        self.assertTrue(negPredict < testSize / 10)


        
if __name__ == '__main__':
    main()